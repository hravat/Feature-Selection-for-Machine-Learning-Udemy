{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import compress\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterMethodDuplicateFeatures:\n",
    "    \n",
    "    def __init__(self,data_path):\n",
    "        self.df=pd.read_csv(data_path)\n",
    "        \n",
    "    def dataframe_info(self):\n",
    "        self.df.info()\n",
    "        \n",
    "    def dataframe_stats(self):\n",
    "        print(self.df.describe().T)\n",
    "        \n",
    "    def __train_test_split_fmb(self):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.df.drop(['target'],axis='columns'),\\\n",
    "                                                            self.df['target'],\\\n",
    "                                                            test_size=0.3, \\\n",
    "                                                            random_state = 0\n",
    "                                                           )\n",
    "        return  X_train, X_test, y_train, y_test\n",
    "    \n",
    "    \n",
    "    def __quasi_constant_manual(self,threshold=0.998):\n",
    "        X_train, X_test, y_train, y_test = self.__train_test_split_fmb()     \n",
    "        col_names=X_train.columns\n",
    "        # Make deep instead of shallow copy to create an entirly new datafeame\n",
    "        quasi_constant_feat=[]    \n",
    "        for col in col_names:\n",
    "            # find the predominant value, that is the value that is shared\n",
    "            # by most observations\n",
    "            predominant = (X_train[col].value_counts() / np.float(\n",
    "            len(X_train))).sort_values(ascending=False).values[0]\n",
    "\n",
    "            # evaluate the predominant feature: do more than 99% of the observations\n",
    "            # show 1 value?\n",
    "            if predominant > threshold:\n",
    "                # if yes, add the variable to the list\n",
    "                quasi_constant_feat.append(col)\n",
    "        \n",
    "        X_train.drop(labels=quasi_constant_feat, axis=1, inplace=True)\n",
    "        X_test.drop(labels=quasi_constant_feat, axis=1, inplace=True)        \n",
    "            \n",
    "        return X_train,X_test\n",
    "    \n",
    "    \n",
    "    def __fit_summary(self,dup_list,before_test_shape,after_test_shape,before_train_shape,after_train_shape):\n",
    "        \n",
    "        print('--------summary of duplicate features------------------')\n",
    "        print('There are a total of '+str(len(dup_list))+\" duplicate features\")\n",
    "        print('--------------------------------------------------------------')\n",
    "        for l in dup_list:\n",
    "            print(l[1]+\" is a duplicate of \"+l[0]+\" and will be dropped\")\n",
    "        print('--------------------------------------------------------------')\n",
    "        print('Train Shape before drop '+str(before_test_shape))\n",
    "        print('Train Shape after drop '+str(after_test_shape))\n",
    "        print('Test Shape before drop '+str(before_train_shape))\n",
    "        print('Test Shape after drop '+str(after_train_shape))\n",
    "    \n",
    "    \n",
    "    def duplicate_features(self):\n",
    "        X_train,X_test = self.__quasi_constant_manual()\n",
    "        \n",
    "        dup_dict={}\n",
    "        dup_list=[]\n",
    "        col_list = X_train.columns\n",
    "        drop_list = []\n",
    "        \n",
    "        for i in  range(len(X_train.columns)):\n",
    "            for j in range(i,len(X_train.columns)):\n",
    "                if (col_list[i] != col_list[j]) and (X_train.iloc[:,i].equals(X_train.iloc[:,j])):\n",
    "                    dup_list.append([col_list[i],col_list[j]])\n",
    "                    drop_list.append(col_list[j])\n",
    "        \n",
    "        before_train_shape = np.shape(X_train)\n",
    "        before_test_shape  = np.shape(X_test)\n",
    "        \n",
    "        X_train.drop(drop_list,axis=1,inplace=True)  \n",
    "        X_test.drop(drop_list,axis=1,inplace=True)\n",
    "        \n",
    "        after_train_shape = np.shape(X_train)\n",
    "        after_test_shape = np.shape(X_test)\n",
    "          \n",
    "        self.__fit_summary(dup_list,before_test_shape,after_test_shape,before_train_shape,after_train_shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj1 = FilterMethodDuplicateFeatures('../data/dataset_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Columns: 301 entries, var_1 to target\n",
      "dtypes: float64(127), int64(174)\n",
      "memory usage: 114.8 MB\n"
     ]
    }
   ],
   "source": [
    "obj1.dataframe_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           count         mean           std  min  25%   50%  75%           max\n",
      "var_1    50000.0     0.002220      0.108145  0.0  0.0  0.00  0.0  9.000000e+00\n",
      "var_2    50000.0     0.000060      0.007746  0.0  0.0  0.00  0.0  1.000000e+00\n",
      "var_3    50000.0    15.593002   1280.571855  0.0  0.0  0.00  0.0  2.079013e+05\n",
      "var_4    50000.0     3.149633      2.740114  0.0  0.0  2.85  3.0  3.528000e+01\n",
      "var_5    50000.0   608.681764  10951.361737  0.0  0.0  0.00  0.0  4.455000e+05\n",
      "...          ...          ...           ...  ...  ...   ...  ...           ...\n",
      "var_297  50000.0     0.000000      0.000000  0.0  0.0  0.00  0.0  0.000000e+00\n",
      "var_298  50000.0     0.003060      0.078808  0.0  0.0  0.00  0.0  3.000000e+00\n",
      "var_299  50000.0    12.462960    832.417622  0.0  0.0  0.00  0.0  1.346667e+05\n",
      "var_300  50000.0  5683.960293  47364.820421  0.0  0.0  0.00  0.0  2.857673e+06\n",
      "target   50000.0     0.039820      0.195538  0.0  0.0  0.00  0.0  1.000000e+00\n",
      "\n",
      "[301 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "obj1.dataframe_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------summary of duplicate features------------------\n",
      "There are a total of 6 duplicate features\n",
      "--------------------------------------------------------------\n",
      "var_148 is a duplicate of var_37 and will be dropped\n",
      "var_199 is a duplicate of var_84 and will be dropped\n",
      "var_296 is a duplicate of var_143 and will be dropped\n",
      "var_250 is a duplicate of var_177 and will be dropped\n",
      "var_232 is a duplicate of var_226 and will be dropped\n",
      "var_269 is a duplicate of var_229 and will be dropped\n",
      "--------------------------------------------------------------\n",
      "Train Shape before drop (15000, 158)\n",
      "Train Shape after drop (15000, 152)\n",
      "Test Shape before drop (35000, 158)\n",
      "Test Shape after drop (35000, 152)\n"
     ]
    }
   ],
   "source": [
    "obj1.duplicate_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
